{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c2172bf-bc61-4b32-80d9-ee695b96325a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-21 05:19:15,254 - __main__ - INFO - [Using Transformers: 4.25.1]\n",
      "2023-01-21 05:19:15,256 - __main__ - INFO - [Using Tokenizers: 0.13.2]\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "from pathlib import Path\n",
    "import transformers \n",
    "import tokenizers\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Setup logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.getLevelName('INFO'), \n",
    "                    handlers=[logging.StreamHandler(sys.stdout)], \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Log versions of dependencies\n",
    "logger.info(f'[Using Transformers: {transformers.__version__}]')\n",
    "logger.info(f'[Using Tokenizers: {tokenizers.__version__}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bf39f-de13-4197-a40a-b0337ab42e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b656f-2407-4c79-a1b8-f13289fb0a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bd376-d05b-413b-b4f0-5cbe5035ef19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b524c1b-b20a-4d44-bdbb-0d4d0fb18184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94cd37a-8c94-44fe-a1ef-cb481fb75a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ec018-8c89-4fbb-b59a-79241b920873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2a342-58cb-40fe-b096-8e0337915cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e292773-a852-42f7-89e5-abe653a42d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425c689-22cb-426a-bcc7-922ab0cecf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28757a9a-89fc-4e17-bc88-454a69729dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00eab0c-205d-4ede-a725-11d6e54fc717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9723df-9d26-48d6-aa73-9abf09b4d8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d24c89-4c96-4c4c-bb92-6d5f698926b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615eabf-c110-4974-b520-d2fb7618ae35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1cce0-2366-445d-bb68-0f7eb09f0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Essentials\n",
    "# LOCAL_INPUT_PATH is mapped to S3 input location for covid news articles \n",
    "LOCAL_INPUT_PATH = '/opt/ml/processing/input' \n",
    "# LOCAL_OUTPUT_PATH is mapped to S3 output location where we want to save the custom vocabulary after training the tokenizer\n",
    "LOCAL_OUTPUT_PATH = '/opt/ml/processing/output'\n",
    "VOCAB_SIZE = 30522\n",
    "\n",
    "# Read input files from local input path \n",
    "logger.info(f'Reading input files from [{LOCAL_INPUT_PATH}/]')\n",
    "paths = [str(x) for x in Path(LOCAL_INPUT_PATH).glob('*.txt')]\n",
    "\n",
    "# Train custom BertWordPiece tokenizer\n",
    "logger.info(f'Training BertWordPiece custom tokenizer using files in {paths}')\n",
    "tokenizer = BertWordPieceTokenizer()\n",
    "tokenizer.train(files=paths, vocab_size=VOCAB_SIZE)\n",
    "\n",
    "# Save trained custom tokenizer to local output path\n",
    "logger.info(f'Saving extracted custom vocabulary to [{LOCAL_OUTPUT_PATH}/]')\n",
    "tokenizer.save_model(LOCAL_OUTPUT_PATH)\n",
    "\n",
    "# Re-create custom tokenizer using vocab from local output path\n",
    "logger.info(f'Re-create BertWordPiece custom tokenizer using extracted custom vocab in {LOCAL_OUTPUT_PATH}')\n",
    "tokenizer = BertWordPieceTokenizer(f'{LOCAL_OUTPUT_PATH}/vocab.txt')\n",
    "\n",
    "# Evaluate custom tokenizer \n",
    "logger.info('Evaluating custom tokenizer')\n",
    "test_sentence = 'covid19 is a virus'\n",
    "logger.info(f'Test sentence: {test_sentence}')\n",
    "tokens = tokenizer.encode(test_sentence).tokens\n",
    "logger.info(f'Encoded sentence: {tokens}')\n",
    "token_id = tokenizer.token_to_id('covid19')\n",
    "logger.info(f'Token ID for token (covid19) = {token_id}')\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "logger.info(f'Vocabulary size = {vocab_size}')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
