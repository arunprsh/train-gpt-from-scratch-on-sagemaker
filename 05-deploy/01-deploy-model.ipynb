{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5489ddfa",
   "metadata": {},
   "source": [
    "#### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b92c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install sagemaker==2.100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5630571",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2316e096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import Session\n",
    "import sagemaker\n",
    "import logging\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb2e06",
   "metadata": {},
   "source": [
    "##### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e7cb10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a5231",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ddae03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using SageMaker: 2.100.0]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using SageMaker: {sagemaker.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd8897",
   "metadata": {},
   "source": [
    "#### Essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29f92e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = Session()\n",
    "ROLE = get_execution_role()\n",
    "S3_BUCKET = session.default_bucket()\n",
    "INSTANCE_TYPE = 'ml.c5.2xlarge'\n",
    "INSTANCE_COUNT = 2\n",
    "TRANSFORMERS_VERSION = '4.17.0'\n",
    "PYTORCH_VERSION = '1.10.2'\n",
    "PYTHON_VERSION = 'py38'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6494ad67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S3 bucket = sagemaker-us-east-1-119174016168\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'S3 bucket = {S3_BUCKET}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b4d1a",
   "metadata": {},
   "source": [
    "#### Deploy custom GPT2 pipeline as a SageMaker endpoint for real-time inference \n",
    "**Note:** You can either deploy the saved GPT2 model or the pipeline tar.gz we created in the previous module (04-evaluation) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9a3655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_TAR_PATH = 'model/model.tar.gz'\n",
    "MODEL_TAR_PATH = 'model/pipelines/pipeline.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1afa1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_model = HuggingFaceModel(model_data=f's3://{S3_BUCKET}/{MODEL_TAR_PATH}', \n",
    "                                     role=ROLE,\n",
    "                                     transformers_version=TRANSFORMERS_VERSION, \n",
    "                                     pytorch_version=PYTORCH_VERSION,\n",
    "                                     py_version=PYTHON_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b1fc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model with name: huggingface-pytorch-inference-2023-01-26-19-40-53-621\n",
      "CreateModel request: {\n",
      "    \"ModelName\": \"huggingface-pytorch-inference-2023-01-26-19-40-53-621\",\n",
      "    \"ExecutionRoleArn\": \"arn:aws:iam::119174016168:role/service-role/AmazonSageMaker-ExecutionRole-20211014T093628\",\n",
      "    \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-cpu-py38-ubuntu20.04\",\n",
      "        \"Environment\": {\n",
      "            \"SAGEMAKER_PROGRAM\": \"\",\n",
      "            \"SAGEMAKER_SUBMIT_DIRECTORY\": \"\",\n",
      "            \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
      "            \"SAGEMAKER_REGION\": \"us-east-1\"\n",
      "        },\n",
      "        \"ModelDataUrl\": \"s3://sagemaker-us-east-1-119174016168/model/pipelines/pipeline.tar.gz\"\n",
      "    }\n",
      "}\n",
      "Creating endpoint-config with name huggingface-pytorch-inference-2023-01-26-19-40-54-230\n",
      "Creating endpoint with name huggingface-pytorch-inference-2023-01-26-19-40-54-230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(initial_instance_count=INSTANCE_COUNT, \n",
    "                                     instance_type=INSTANCE_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee6073a",
   "metadata": {},
   "source": [
    "#### Invoke endpoint for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50fa9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'China is effectively in a lockdown. this is far from the worst possible situation. this month, for example, there were more than 25,000 covid-19 deaths and hospitals were overflowing with patients. â€œ everyone is panicking. at the beginning'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'inputs': 'China is effectively in a lockdown.'}\n",
    "response = predictor.predict(data)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5891e6",
   "metadata": {},
   "source": [
    "#### Delete endpoint (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52125f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb174c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.8-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
