{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbeaf42d-27fb-4883-938a-7c16e1b23c23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finetuning OOO  GPT2 for text classification \n",
    "\n",
    "Based on implementation at: https://www.kaggle.com/code/baekseungyun/gpt-2-with-huggingface-pytorch\n",
    "\n",
    "http://mohitmayank.com/a_lazy_data_science_guide/natural_language_processing/GPTs/\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/guide-to-fine-tuning-text-generation-models-gpt-2-gpt-neo-and-t5-dc5de6b3bc5e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a267a1b-093e-4dbf-a32f-b1071de2febd",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf3178-6b13-42db-80d3-90981414616b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install transformers\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18674937-d215-4af6-a5f1-157a3d763089",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c15820e-d939-48b1-8f4b-f52db814641a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments\n",
    "from transformers import GPT2LMHeadModel\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import GPT2Config\n",
    "from transformers import set_seed\n",
    "from transformers import Trainer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import logging\n",
    "import sklearn\n",
    "import pandas\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2bd3e6-1ecb-41dd-b349-7a424fe16bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de90af2-7043-4ff9-b5d2-ce81c5a600dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using transformers version: 4.18.0]\n",
      "[Using sklearn version: 0.24.2]\n",
      "[Using torch version: 1.8.1]\n",
      "[Using pandas version: 1.1.5]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using transformers version: {transformers.__version__}]')\n",
    "logger.info(f'[Using sklearn version: {sklearn.__version__}]')\n",
    "logger.info(f'[Using torch version: {torch.__version__}]')\n",
    "logger.info(f'[Using pandas version: {pandas.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81857c-3ca6-4409-84b4-31f46580ed92",
   "metadata": {},
   "source": [
    "#### 1. Setup GPT2 model & tokenizer   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c96447b-51e0-41b8-93aa-9a0b03b2d1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e35c7-95ad-41fb-b531-c097e7130d2a",
   "metadata": {},
   "source": [
    "Setup GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5a3579-d2f5-47d6-a7e2-30c891ef9026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7dbf2e-e96c-40e5-92dc-36b4429819f6",
   "metadata": {},
   "source": [
    "##### Setup GPT2 tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf559370-975e-43af-905c-74fa1949ed04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='gpt2', vocab_size=50257, model_max_len=512, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
    "                                          bos_token='<|startoftext|>',\n",
    "                                          eos_token='<|endoftext|>', \n",
    "                                          pad_token='<|pad|>')\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.model_max_length = 512\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "465be071-30bf-43e8-818d-9ebb7746d767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50259"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b390b97-d091-41ac-b2c2-a1ff5753ea4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resizes the token embeddings of the model to match the number of tokens in the tokenizer\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c28602-b4ab-42a0-8b1b-1039a35bf14c",
   "metadata": {},
   "source": [
    "#### 2. Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1309bb5-de35-4823-a098-33bc75535fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, txt_list, label_list, tokenizer, max_length):          \n",
    "        self.input_ids = []\n",
    "        self.attention_mask = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Define label map\n",
    "        label_map = {0 : 'business', 1 : 'esg', 2 : 'general', 3 : 'science', 4 : 'tech'}\n",
    "        \n",
    "        # Iterate through the dataset\n",
    "        for txt, label in zip(txt_list, label_list):\n",
    "            # Prepare the text\n",
    "            prep_txt = f'<|startoftext|>tweet: {txt}<|pad|>sentiment: {label_map[label]}<|endoftext|>'\n",
    "            # Tokenize the text\n",
    "            encodings_dict = tokenizer(prep_txt, \n",
    "                                       truncation=True,\n",
    "                                       max_length=max_length, \n",
    "                                       padding='max_length')\n",
    "            # Append the tokenized text to the list\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attention_mask.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "            self.labels.append(label_map[label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_mask[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf70968e-e7d8-4ebf-8301-6e38e13c695f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mysterious respiratory virus strikes 44 people...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coronavirus impact on tech supply chains minim...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hackers imitating cdc, who with coronavirus ph...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new virus identified as likely cause of myster...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new sars related virus, wuhan pneumonia, ideni...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  mysterious respiratory virus strikes 44 people...      2\n",
       "1  coronavirus impact on tech supply chains minim...      4\n",
       "2  hackers imitating cdc, who with coronavirus ph...      4\n",
       "3  new virus identified as likely cause of myster...      3\n",
       "4  new sars related virus, wuhan pneumonia, ideni...      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './covid_articles_clf_data.csv'\n",
    "df = pd.read_csv(file_path, names=['text', 'label'])\n",
    "#df = df.sample(50000, random_state=1)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65cbc979-0d07-4ab4-933b-735a1c5aa926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].tolist(), \n",
    "                                                    df['label'].tolist(), \n",
    "                                                    shuffle=True, \n",
    "                                                    test_size=0.05, \n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60d91233-8ac8-4018-bb67-3cf6f1cb37f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train, tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea378622-6306-46c1-b60e-4852bda8d7c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 133308\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-22 13:54:34.079 pytorch-1-8-gpu-py3-ml-g5-12xlarge-a2b82b571c5bb70d3876e8ca70c8:19349 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-01-22 13:54:34.110 pytorch-1-8-gpu-py3-ml-g5-12xlarge-a2b82b571c5bb70d3876e8ca70c8:19349 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4166' max='4166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4166/4166 1:02:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.131700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.126900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output/checkpoint-4166\n",
      "Configuration saved in ./output/checkpoint-4166/config.json\n",
      "Model weights saved in ./output/checkpoint-4166/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4166, training_loss=0.16531857652155985, metrics={'train_runtime': 3755.1506, 'train_samples_per_second': 35.5, 'train_steps_per_second': 1.109, 'total_flos': 3.4832318201856e+16, 'train_loss': 0.16531857652155985, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir='./output', \n",
    "                                  num_train_epochs=1,  \n",
    "                                  optim='adamw_torch', \n",
    "                                  save_strategy='epoch', \n",
    "                                  #evaluation_strategy='epoch', \n",
    "                                  per_device_train_batch_size=8, \n",
    "                                  #per_device_eval_batch_size=8, \n",
    "                                  warmup_steps=100, \n",
    "                                  weight_decay=0.01, \n",
    "                                  logging_dir='logs')\n",
    "\n",
    "# start training\n",
    "Trainer(model=model, \n",
    "        args=training_args, \n",
    "        train_dataset=train_dataset, \n",
    "        #eval_dataset=test_dataset,\n",
    "        data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                    'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                    'labels': torch.stack([f[0] for f in data])}).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ac0560-0381-45e2-9d20-45721086d985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c2b6f1-e884-439b-93d4-2dc5c8cbe648",
   "metadata": {},
   "source": [
    "#### Test for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd561fbd-02b4-42a1-9011-f41dd0a0e2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./output/checkpoint-4166/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"./output/checkpoint-4166\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50259\n",
      "}\n",
      "\n",
      "loading weights file ./output/checkpoint-4166/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./output/checkpoint-4166.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "# Load the fine-tuned GPT-2 model\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained('./output/checkpoint-4166')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088933b-7dc0-4651-89ef-b2cb8bf6971b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1261e136-16df-45d3-a72b-eb5f191b0063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4510e+02, -1.3709e+02, -1.4375e+02,  ..., -1.4558e+02,\n",
       "          -5.6403e+00,  1.0422e+01],\n",
       "         [-1.5525e+01, -1.5560e+01, -1.6763e+01,  ..., -1.1477e+01,\n",
       "          -1.7757e+00,  9.8000e-02],\n",
       "         [-1.6649e+01, -1.5544e+01, -1.8423e+01,  ..., -1.7433e+01,\n",
       "          -3.2185e+00, -3.9600e-01],\n",
       "         ...,\n",
       "         [-3.0732e+01, -3.3927e+01, -3.6025e+01,  ..., -2.7694e+01,\n",
       "          -2.2712e+00, -6.4070e-01],\n",
       "         [ 1.0196e+01,  8.9675e+00,  8.0908e+00,  ...,  1.5406e+01,\n",
       "          -1.8195e+00,  2.0543e+00],\n",
       "         [-1.0244e+01, -1.0119e+01, -1.1309e+01,  ..., -1.1721e+00,\n",
       "          -1.5378e+00,  2.6751e-01]]], grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = \"Tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nSentiment:\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68f69e8e-a027-47d4-a854-99474fca365c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./output/checkpoint-4166/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"./output/checkpoint-4166\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50259\n",
      "}\n",
      "\n",
      "loading configuration file ./output/checkpoint-4166/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"./output/checkpoint-4166\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50259\n",
      "}\n",
      "\n",
      "loading weights file ./output/checkpoint-4166/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./output/checkpoint-4166.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: tech'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: tech'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: business'},\n",
       " {'generated_text': 'tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment: general'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='./output/checkpoint-4166', tokenizer='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"tweet: beijing reports 21 new covid-19 cases in city as of june 17\\nsentiment:\", max_length=128, num_return_sequences=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cef3c0-8065-426a-9fdf-0f304aa0a020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc0cc404-5b73-41fa-954d-f06677a6d16e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 27])\n",
      "tweet: after coronavirus: california liberals say returning to normal won’ t be enough\n",
      "sentiment: business\n",
      "torch.Size([1, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet: visitors to shanghai disneyland become ‘ envy of the whole world’ after park reopens at one-third capacity following coronavirus shutdown\n",
      "sentiment: business\n",
      "torch.Size([1, 18])\n",
      "tweet: zoom video stock surges as coronavirus fears deepen\n",
      "sentiment: business\n",
      "torch.Size([1, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet: detroit to be first to deploy abbott labs’ 5-minute covid-19 test, mayor says\n",
      "sentiment: business\n",
      "torch.Size([1, 40])\n",
      "tweet: le test salivaire covid-19 d'intelligent fingerprinting reçoit le marquage ce et devient disponible à la vente\n",
      "sentiment: general\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# set the model to eval mode\n",
    "_ = model.eval()\n",
    "\n",
    "# run model inference on all test data\n",
    "original_label, predicted_label, original_text, predicted_text = [], [], [], []\n",
    "label_map = {0 : 'business', 1 : 'esg', 2 : 'general', 3 : 'science', 4 : 'tech'}\n",
    "# iter over all of the test data\n",
    "i = 0\n",
    "for text, label in zip(X_test, y_test):\n",
    "    text = text[0:512]\n",
    "    # create prompt (in compliance with the one used during training)\n",
    "    prompt = f'<|startoftext|>tweet: {text}\\nsentiment:'\n",
    "    # generate tokens\n",
    "    generated = tokenizer(f\"{prompt}\", return_tensors=\"pt\").input_ids\n",
    "    print(generated.shape)\n",
    "    # perform prediction\n",
    "    sample_outputs = model.generate(generated, \n",
    "                                    do_sample=True, \n",
    "                                    top_k=50, \n",
    "                                    max_length=512, \n",
    "                                    top_p=0.90, \n",
    "                                    temperature=0.01)\n",
    "\n",
    "    \n",
    "    # decode the predicted tokens into texts\n",
    "    pred_text  = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "    print(pred_text)\n",
    "    # extract the predicted sentiment\n",
    "    try:\n",
    "        pred_sentiment = re.findall(\"\\nsentiment: (.*)\", pred_text)[-1]\n",
    "    except:\n",
    "        pred_sentiment = \"None\"\n",
    "    # append results\n",
    "    original_label.append(label_map[label])\n",
    "    predicted_label.append(pred_sentiment)\n",
    "    original_text.append(text)\n",
    "    predicted_text.append(pred_text)\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "# transform result into dataframe\n",
    "df = pd.DataFrame({'original_text': original_text, 'predicted_label': predicted_label, \n",
    "                    'original_label': original_label, 'predicted_text': predicted_text})\n",
    "\n",
    "# predict the accuracy\n",
    "print(f1_score(original_label, predicted_label, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25040d8d-cc01-4df2-86bb-e88320c84d00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>original_label</th>\n",
       "      <th>predicted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after coronavirus: california liberals say ret...</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>tweet: after coronavirus: california liberals ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>visitors to shanghai disneyland become ‘ envy ...</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>tweet: visitors to shanghai disneyland become ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zoom video stock surges as coronavirus fears d...</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>tweet: zoom video stock surges as coronavirus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detroit to be first to deploy abbott labs’ 5-m...</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>tweet: detroit to be first to deploy abbott la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>le test salivaire covid-19 d'intelligent finge...</td>\n",
       "      <td>general</td>\n",
       "      <td>general</td>\n",
       "      <td>tweet: le test salivaire covid-19 d'intelligen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text predicted_label  \\\n",
       "0  after coronavirus: california liberals say ret...        business   \n",
       "1  visitors to shanghai disneyland become ‘ envy ...        business   \n",
       "2  zoom video stock surges as coronavirus fears d...        business   \n",
       "3  detroit to be first to deploy abbott labs’ 5-m...        business   \n",
       "4  le test salivaire covid-19 d'intelligent finge...         general   \n",
       "\n",
       "  original_label                                     predicted_text  \n",
       "0       business  tweet: after coronavirus: california liberals ...  \n",
       "1       business  tweet: visitors to shanghai disneyland become ...  \n",
       "2       business  tweet: zoom video stock surges as coronavirus ...  \n",
       "3       business  tweet: detroit to be first to deploy abbott la...  \n",
       "4        general  tweet: le test salivaire covid-19 d'intelligen...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feb68704-9a7b-486f-8bb8-7b09c8c72be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after coronavirus: california liberals say returning to normal won’ t be enough\n",
      "visitors to shanghai disneyland become ‘ envy of the whole world’ after park reopens at one-third capacity following coronavirus shutdown\n",
      "zoom video stock surges as coronavirus fears deepen\n",
      "detroit to be first to deploy abbott labs’ 5-minute covid-19 test, mayor says\n",
      "le test salivaire covid-19 d'intelligent fingerprinting reçoit le marquage ce et devient disponible à la vente\n"
     ]
    }
   ],
   "source": [
    "for text in df['original_text']:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2a760e7-ffe9-4bec-b3a2-ab1108118493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet: after coronavirus: california liberals say returning to normal won’ t be enough\n",
      "sentiment: business\n",
      "tweet: visitors to shanghai disneyland become ‘ envy of the whole world’ after park reopens at one-third capacity following coronavirus shutdown\n",
      "sentiment: business\n",
      "tweet: zoom video stock surges as coronavirus fears deepen\n",
      "sentiment: business\n",
      "tweet: detroit to be first to deploy abbott labs’ 5-minute covid-19 test, mayor says\n",
      "sentiment: business\n",
      "tweet: le test salivaire covid-19 d'intelligent fingerprinting reçoit le marquage ce et devient disponible à la vente\n",
      "sentiment: general\n"
     ]
    }
   ],
   "source": [
    "for text in df['predicted_text']:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f8cef4-b86c-4d12-843b-aa7b869ec5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad609a-cdb1-42e8-b9fd-897186542e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c6b6e-2e98-4d70-89a6-5aca2766707a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb270f5-549c-4bce-ab21-395987310715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae319c2-260f-4e1d-97b6-e9a823e4a717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830e1d3-b8ce-43e1-b32a-d0bbd1a382c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g5.12xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.8-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
